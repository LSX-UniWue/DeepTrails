{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../../code-2023-deephyptrails/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from Code.Dataset.ReviewDataset import ReviewsDataset, RFAMZWalkDataset\n",
    "from Code.Models.RandoLMForest import generate, get_probabilities_per_token\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import hdbscan\n",
    "import umap\n",
    "import umap.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"deeptrails/data/amz_real_data/randoLM_fkt.pkl\", \"rb\"))\n",
    "model, model.feature_ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sichere bindungsstil\n",
    "- nur friendship complete => rest friendship radius\n",
    "- cluster raus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ReviewsDataset(\"deeptrails/data/amz_real_data/dataset.jsonl\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_available_features = [dict(tuple(sorted(d[0][-1].items()))) for d in dataset.annotated_walks]\n",
    "list_of_available_features = list(set([tuple(sorted(d.items())) for d in list_of_available_features]))\n",
    "list_of_available_features = [dict(d) for d in list_of_available_features]\n",
    "len(list_of_available_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature_indices in list_of_available_features:\n",
    "    print(generate(model, [0], feature_indices, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = RFAMZWalkDataset(dataset.annotated_walks, walk_type=\"fkt\", args=dataset.args)\n",
    "probs = get_probabilities_per_token(model, ds.inputs, ds.targets)\n",
    "probs_by_token = {i: [] for i in range(102)}\n",
    "for p, t in zip(probs, ds.targets):\n",
    "    probs_by_token[t].append(p)\n",
    "\n",
    "probs_by_token = {i: np.mean(p) for i, p in probs_by_token.items()}\n",
    "plt.figure()\n",
    "plt.plot(probs_by_token.keys(), probs_by_token.values())\n",
    "plt.xlabel(\"Token\")\n",
    "plt.ylabel(\"Probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "targets = []\n",
    "feature_indices = []\n",
    "walk_indices = []\n",
    "\n",
    "for feature_index, feature in enumerate(list_of_available_features):\n",
    "    fake_dataset = ReviewsDataset(\"deeptrails/data/amz_real_data/dataset.jsonl\")\n",
    "    target_dataset = ReviewsDataset(\"deeptrails/data/amz_real_data/dataset.jsonl\")\n",
    "    for walk_index in range(len(fake_dataset.annotated_walks)):\n",
    "        target_dataset.annotated_walks = [fake_dataset.annotated_walks[walk_index]]\n",
    "        for walk in target_dataset.annotated_walks:\n",
    "            for step in walk:\n",
    "                step[-1] = feature\n",
    "        fake_ds = RFAMZWalkDataset(target_dataset.annotated_walks, walk_type=\"fkt\", args=dataset.args)\n",
    "        inputs.extend(fake_ds.inputs)\n",
    "        targets.extend(fake_ds.targets)\n",
    "        feature_indices.extend([feature_index] * len(fake_ds.inputs))\n",
    "        walk_indices.extend([walk_index] * len(fake_ds.inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = get_probabilities_per_token(model, inputs, targets)\n",
    "df = pd.DataFrame(\n",
    "    {\"walk_index\": walk_indices, \"feature_index\": feature_indices, \"input\": inputs, \"targets\": targets, \"prob\": probs}\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_observations_per_feature_and_walk_and_token = np.zeros(\n",
    "    (\n",
    "        len(list_of_available_features),\n",
    "        len(dataset.annotated_walks),\n",
    "        model.n_features_in_,\n",
    "    )\n",
    ")\n",
    "\n",
    "for _, values in (\n",
    "    df.groupby([\"walk_index\", \"feature_index\", \"targets\"])[\"prob\"].mean().to_frame().reset_index().iterrows()\n",
    "):\n",
    "    probability_observations_per_feature_and_walk_and_token[\n",
    "        int(values[\"feature_index\"]),\n",
    "        int(values[\"walk_index\"]),\n",
    "        int(values[\"targets\"]),\n",
    "    ] = values[\"prob\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot heatmap of probabilities per feature and walk\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(\n",
    "    np.mean(probability_observations_per_feature_and_walk_and_token, axis=-1),\n",
    "    # xticklabels=range(len(dataset.annotated_walks)),\n",
    "    # yticklabels=list_of_available_features,\n",
    "    cmap=\"Blues\",\n",
    "    # vmin=0,\n",
    "    # vmax=1,\n",
    ")\n",
    "plt.xlabel(\"Walk\")\n",
    "plt.ylabel(\"Feature combination\")\n",
    "plt.title(\"Probability of sequence given feature\")\n",
    "plt.savefig(\"code-2023-deephyptrails/data/potential-paper-figures/amz-heatmap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(\n",
    "    np.mean(probability_observations_per_feature_and_walk_and_token, axis=-1).T,\n",
    "    # xticklabels=range(len(dataset.annotated_walks)),\n",
    "    # yticklabels=list_of_available_features,\n",
    "    cmap=\"Blues\",\n",
    "    # vmin=0,\n",
    "    # vmax=1,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Feature combination\")\n",
    "plt.ylabel(\"Walk\")\n",
    "\n",
    "plt.title(\"Probability of sequence given feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_clusters = hdbscan.HDBSCAN(cluster_selection_method=\"leaf\").fit(\n",
    "    np.mean(probability_observations_per_feature_and_walk_and_token, axis=-1)\n",
    ")\n",
    "mapper = umap.UMAP()\n",
    "reduced_data = mapper.fit_transform(np.mean(probability_observations_per_feature_and_walk_and_token, axis=-1))\n",
    "reduced_cluster = hdbscan.HDBSCAN().fit(reduced_data)\n",
    "umap.plot.points(mapper, labels=reduced_cluster.labels_)\n",
    "plt.title(\"feature combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature_label in range(max(feature_clusters.labels_) + 1):\n",
    "    print(\"Feature label:\", feature_label)\n",
    "    print(\"Number of feature combinations:\", len(np.where(feature_clusters.labels_ == feature_label)[0]))\n",
    "    print(\n",
    "        \"Feature combinations:\",\n",
    "        \"\\n\".join({str(list_of_available_features[i]) for i in np.where(feature_clusters.labels_ == feature_label)[0]}),\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_clusters = hdbscan.HDBSCAN(cluster_selection_method=\"leaf\").fit(\n",
    "    np.mean(probability_observations_per_feature_and_walk_and_token, axis=-1).T\n",
    ")\n",
    "mapper = umap.UMAP()\n",
    "mapper.fit_transform(np.mean(probability_observations_per_feature_and_walk_and_token, axis=-1).T)\n",
    "umap.plot.points(mapper, labels=walk_clusters.labels_)\n",
    "plt.title(\"walks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for walk_label in range(max(walk_clusters.labels_) + 1):\n",
    "    print(\"Walk label:\", walk_label)\n",
    "    print(\"Number of walks:\", len(np.where(walk_clusters.labels_ == walk_label)[0]))\n",
    "    print(\n",
    "        \"Walks:\",\n",
    "        \"\\n\".join(\n",
    "            {\n",
    "                str([s[:-1] for s in dataset.annotated_walks[i]])\n",
    "                for i in np.where(walk_clusters.labels_ == walk_label)[0]\n",
    "            }\n",
    "        ),\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = RFAMZWalkDataset(dataset.annotated_walks, walk_type=\"fkt\", args=dataset.args)\n",
    "probs = get_probabilities_per_token(model, ds.inputs, ds.targets)\n",
    "probs_by_index = {i: [] for i in range(200)}\n",
    "for p, walk_index in zip(probs, ds.indices):\n",
    "    probs_by_index[walk_index].append(p)\n",
    "\n",
    "probs_by_index = {i: np.mean(p) for i, p in probs_by_index.items()}\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(probs_by_index.keys(), probs_by_index.values())\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
