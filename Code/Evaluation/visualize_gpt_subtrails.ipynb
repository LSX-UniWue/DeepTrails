{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../../projects/code-2023-deephyptrails/\")  # you might need to insert the absolute path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from Code.Models.LightningGPT import GPT, GPTConfig\n",
    "from Code.Dataset.ReviewDataset import ReviewsDataset, AMZWalkDataset\n",
    "import torch\n",
    "import umap\n",
    "import umap.plot\n",
    "import numpy as np\n",
    "import torch\n",
    "import hdbscan\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some settings\n",
    "dataset_path = \"code-2023-deephyptrails/data/all-data/dataset-subtrails.jsonl\"\n",
    "model_path = \"code-2023-deephyptrails/data/all-data/model_data-subtrails-annotated-walks_final_200a7298.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_categories(walk: list, new_category_dict: dict):\n",
    "    new_walk = []\n",
    "    for node in walk:\n",
    "        new_walk.append([node[0], node[1], node[2], new_category_dict])\n",
    "    return new_walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ReviewsDataset(dataset_path)\n",
    "all_walkies, _ = dataset.get_walks()\n",
    "all_walkies = all_walkies['annotated_walks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_category_combinations = [x[0][3] for x in all_walkies]\n",
    "category_set = set([tuple(x.values()) for x in all_category_combinations])\n",
    "all_category_combinations = [{k: v for k, v in zip(all_category_combinations[0].keys(), curr_set)} for curr_set in category_set]\n",
    "all_category_combinations = sorted(all_category_combinations, key=lambda x: (x['cat1'], x['cat2'], x['cat3'], x['cat4']), reverse=True)\n",
    "feature_index = {k: v for k, v in enumerate(all_category_combinations)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walkies = []\n",
    "walk_idx = 0\n",
    "walk_index = {}\n",
    "for idx in [1, 2, 3, 4]:\n",
    "    current_walkies = [x for x in all_walkies if x[0][3][f'cat{idx}'] == 1][:10]\n",
    "    for current_walky in current_walkies:\n",
    "        walk_index[walk_idx] = [0] + [x[2] + 2 for x in current_walky] + [1] # +2 for BOS and EOS\n",
    "        walk_idx += 1\n",
    "        for current_dict in all_category_combinations:\n",
    "            walkies.append(change_categories(current_walky, current_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPTConfig(\n",
    "    block_size=20 + 1,  # to be able to predict EOS in the end\n",
    "    vocab_size=100 + 2,  # 0 for BOS and 1 for EOS, all other tokens are thus shifted by 2\n",
    "    n_layer=4,\n",
    "    n_head=4,\n",
    "    n_embd=16,\n",
    "    feature_embd_dim=12,\n",
    "    bias=False,\n",
    ")\n",
    "model = GPT(config)\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu'))[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "eval_dict = {}\n",
    "dataset = AMZWalkDataset(\n",
    "    walkies,\n",
    "    walk_type=f\"subtrails-test\",\n",
    "    args=dataset.args\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=0,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    ")\n",
    "losses = []\n",
    "for i, batch in enumerate(dataloader):\n",
    "    targets = batch[0][:, 1:].contiguous()\n",
    "    input = batch[0][:, :-1].contiguous()\n",
    "    features = batch[1]\n",
    "    last_hidden_state = model(idx=input, targets=targets, features=features, return_last_hidden_state=True)\n",
    "    curr = {\"idx:\": i, \"loss\": last_hidden_state['loss'].item(), \"features\": features, \"walk\": batch[0]}\n",
    "    losses.append(curr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_by_walk_or_feature(idx_dict: dict, walk_or_feature):\n",
    "    for k, v in idx_dict.items():\n",
    "        if walk_or_feature == v:\n",
    "            return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazing_matrix = np.zeros((len(feature_index), len(walk_index)))\n",
    "for i_want_to_go_home in losses:\n",
    "    idx = get_idx_by_walk_or_feature(feature_index, i_want_to_go_home['features'])\n",
    "    idy = get_idx_by_walk_or_feature(walk_index, i_want_to_go_home['walk'].tolist()[0])\n",
    "    amazing_matrix[idx, idy] = i_want_to_go_home['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# plot heatmap of probabilities per feature and walk\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(\n",
    "    amazing_matrix,\n",
    "    # xticklabels=range(len(dataset.annotated_walks)),\n",
    "    # yticklabels=list_of_available_features,\n",
    "    cmap=\"Blues\",\n",
    "    # vmin=0,\n",
    "    # vmax=1,\n",
    ")\n",
    "plt.xlabel(\"Walk\")\n",
    "plt.ylabel(\"Feature combination\")\n",
    "# plt.title(\"Probability of sequence given feature\")\n",
    "plt.savefig(\"code-2023-deephyptrails/data/potential-paper-figures/subtrails_heatmap.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labes = np.array([\"Cat1/Even\"] * 4 + [\"Cat2/Odd\"] * 4 + [\"Cat3/First Even\"] * 4 + [\"Cat4/First Odd\"] * 4)\n",
    "mapper = umap.UMAP(n_neighbors=4)\n",
    "mapper.fit_transform(amazing_matrix)\n",
    "umap.plot.points(mapper, labels=cluster_labes)\n",
    "plt.title(\"feature combinations\")\n",
    "plt.savefig(\"code-2023-deephyptrails/data/potential-paper-figures/subtrails_synthetic_feature.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labes = np.array([\"Even\"] * 10 + [\"Odd\"] * 10 + [\"First Even\"] * 10 + [\"First Odd\"] * 10)\n",
    "mapper = umap.UMAP()\n",
    "mapper.fit_transform(amazing_matrix.T)\n",
    "umap.plot.points(mapper, labels=cluster_labes)\n",
    "plt.title(\"Walks\")\n",
    "plt.savefig(\"code-2023-deephyptrails/data/potential-paper-figures/subtrails_synthetic_walks.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
