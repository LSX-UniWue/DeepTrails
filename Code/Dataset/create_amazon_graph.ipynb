{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time2str(timestamp):\n",
    "    if timestamp.hour < 6:\n",
    "        return \"night\"\n",
    "    elif timestamp.hour < 12:\n",
    "        return \"morning\"\n",
    "    elif timestamp.hour < 18:\n",
    "        return \"afternoon\"\n",
    "    else:\n",
    "        return \"evening\"\n",
    "\n",
    "\n",
    "def time2int(timestamp):\n",
    "    # morning, afternoon, evening, night\n",
    "    if timestamp.hour < 6:\n",
    "        return 0\n",
    "    elif timestamp.hour < 12:\n",
    "        return 1\n",
    "    elif timestamp.hour < 18:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/janpf/projects/hiwi/jörn_alexa/jan/all_data_categorized.csv\")\n",
    "df[\"datum\"] = pd.to_datetime(df[\"datum\"])\n",
    "df[\"timeofday\"] = df[\"datum\"].apply(time2int)\n",
    "df = df.sort_values(by=\"datum\")\n",
    "df.drop(columns=[\"kategorie_single\", \"funktion_single\"], inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.read_excel(\n",
    "    \"/Users/janpf/projects/hiwi/jörn_alexa/graphenstuff/kontrollierte_korrekte_daten/Datensatz_LZS (1).xlsx\"\n",
    ")\n",
    "list(feature_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = feature_df[\n",
    "    [\n",
    "        \"G003_01\",\n",
    "        # \"RSQ.Skala_Angst.vor.Nähe_D002\",\n",
    "        # \"RSQ.Skala_fehlendes.Vertrauen_D002\",\n",
    "        \"lonliness_emotional_D009\",\n",
    "        \"lonliness_social_D009\",\n",
    "        \"NEOFFI_N_D008\",\n",
    "        \"Uncanny.Valley_Humaness_A010_E2\",\n",
    "        \"disclosiveness.towardsVA_amount_E006_E2\",\n",
    "        \"bailenson.scale_social.presence_A013_E2\",\n",
    "        \"PSI_cognitive_A015_E2\",\n",
    "        \"Intimate.Friendship_complete.scale_E001_E2\",\n",
    "        # \"Intimate.Friendship_Frankness_E001_E2\",\n",
    "        # \"Intimate.Friendship_Sensitivity_E001_E2\",\n",
    "        # \"Intimate.Friendship_Attachment_E001_E2\",\n",
    "        # \"Intimate.Friendship_Exclusiveness_E001_E2\",\n",
    "        # \"Intimate.Friendship_Giving_E001_E2\",\n",
    "        # \"Intimate.Friendship_Trust_E001_E2\",\n",
    "        # \"Intimate.Friendship_complete.scale_E001_E2\",\n",
    "        # \"cluster_neu\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "feature_df[\"nutzer\"] = \"empty\"\n",
    "\n",
    "\n",
    "for i in set(df[\"user\"]):\n",
    "    for j in range(0, len(feature_df[\"G003_01\"])):\n",
    "        if i[0:4] == feature_df[\"G003_01\"][j]:\n",
    "            feature_df[\"nutzer\"][j] = i\n",
    "\n",
    "\n",
    "feature_df = feature_df.drop(feature_df[feature_df[\"nutzer\"] == \"empty\"].index)\n",
    "feature_df = feature_df.reset_index()\n",
    "feature_df = feature_df.drop(14).reset_index(drop=True)\n",
    "feature_df.dropna(inplace=True)\n",
    "if \"cluster_neu\" in feature_df.columns:\n",
    "    feature_df[\"cluster\"] = feature_df[\"cluster_neu\"].astype(int)\n",
    "    feature_df.drop(columns=[\"cluster_neu\"], inplace=True)\n",
    "feature_df.drop(columns=[\"index\", \"G003_01\"], inplace=True)\n",
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkt2id = {\"start\": 0} | {fkt: i + 1 for i, fkt in enumerate(df[\"funktion_single_antwort\"].value_counts().index)}\n",
    "kat2id = {\"start\": 0} | {kat: i + 1 for i, kat in enumerate(df[\"kategorie_single_antwort\"].value_counts().index)}\n",
    "fkt2id, kat2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walks = []\n",
    "# generate random walks over the data\n",
    "# a walk continues as long as a user is active again within 10 minutes\n",
    "# a walk is a list of tuples (user, function, category, timeofday, weekday)\n",
    "for user in df[\"user\"].value_counts().index:\n",
    "    user_df = df[df[\"user\"] == user]\n",
    "    features = feature_df[feature_df[\"nutzer\"] == user]\n",
    "    if len(features) == 0:\n",
    "        print(f\"no features for user {user}\")\n",
    "        continue\n",
    "    elif len(features) > 1:\n",
    "        print(f\"more than one feature for user {user}\")\n",
    "        continue\n",
    "    last_time = None\n",
    "    current_walk = []\n",
    "    for _, row in user_df.iterrows():\n",
    "        if row[\"funktion_single_antwort\"] in [\n",
    "            # \"Gerät missversteht oder kann Befehl nicht ausführen\",\n",
    "            \"multiple\",\n",
    "        ] or row[\"kategorie_single_antwort\"] in [\n",
    "            # \"Verfügbarkeit / Misserfolg\",\n",
    "            \"multiple\",\n",
    "        ]:\n",
    "            continue\n",
    "        if last_time is None or ((row[\"datum\"] - last_time).seconds / 60) < 15:\n",
    "            current_walk.append(\n",
    "                (\n",
    "                    user,\n",
    "                    row[\"funktion_single_antwort\"],\n",
    "                    row[\"kategorie_single_antwort\"],\n",
    "                    {\n",
    "                        \"timeofday\": row[\"timeofday\"],\n",
    "                        \"weekday\": row[\"wochentag\"],\n",
    "                    }\n",
    "                    | features.iloc[0].to_dict(),\n",
    "                )\n",
    "            )\n",
    "            last_time = row[\"datum\"]\n",
    "        else:\n",
    "            if len(current_walk) > 1:\n",
    "                walks.append(current_walk)\n",
    "            current_walk = [\n",
    "                (\n",
    "                    user,\n",
    "                    row[\"funktion_single_antwort\"],\n",
    "                    row[\"kategorie_single_antwort\"],\n",
    "                    {\n",
    "                        \"timeofday\": row[\"timeofday\"],\n",
    "                        \"weekday\": row[\"wochentag\"],\n",
    "                    }\n",
    "                    | features.iloc[0].to_dict(),\n",
    "                )\n",
    "            ]\n",
    "        del current_walk[-1][-1][\"nutzer\"]\n",
    "walks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(walks)), Counter([len(walk) for walk in walks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = \"/Users/janpf/projects/deeptrails/data/amz_real_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "dataset[\"args\"] = {}\n",
    "dataset[\"annotated_walks\"] = walks\n",
    "dataset[\"args\"][\"fkt2id\"] = fkt2id\n",
    "dataset[\"args\"][\"kat2id\"] = kat2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{out}/dataset.jsonl\", \"w\") as f:\n",
    "    json.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_walks = []\n",
    "for walk in walks:\n",
    "    for i, step in enumerate(walk):\n",
    "        flat_walks.append(\n",
    "            {\n",
    "                \"user\": step[0],\n",
    "                \"funktion\": step[1],\n",
    "                \"previous_funktion\": walk[i - 1][1] if i > 0 else \"start\",\n",
    "                \"kategorie\": step[2],\n",
    "                \"previous_kategorie\": walk[i - 1][2] if i > 0 else \"start\",\n",
    "                **step[3],\n",
    "            }\n",
    "        )\n",
    "        # del flat_walks[-1][\"nutzer\"]\n",
    "len(flat_walks), flat_walks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kat_walks = []\n",
    "attributes = None\n",
    "\n",
    "for walk in flat_walks:\n",
    "    kat_walks.append(dict(walk.items()))\n",
    "    del kat_walks[-1][\"user\"]\n",
    "    kat_walks[-1][\"from\"] = kat2id[kat_walks[-1][\"previous_kategorie\"]]\n",
    "    del kat_walks[-1][\"previous_kategorie\"]\n",
    "    kat_walks[-1][\"to\"] = kat2id[kat_walks[-1][\"kategorie\"]]\n",
    "    del kat_walks[-1][\"kategorie\"]\n",
    "    del kat_walks[-1][\"previous_funktion\"]\n",
    "    del kat_walks[-1][\"funktion\"]\n",
    "    if attributes is None:\n",
    "        attributes = list(kat_walks[-1].keys())\n",
    "    else:\n",
    "        assert attributes == list(kat_walks[-1].keys())\n",
    "    kat_walks[-1] = list(kat_walks[-1].values())\n",
    "\n",
    "print(kat_walks[0])\n",
    "\n",
    "arff.dump(\n",
    "    \"/Users/janpf/projects/deeptrails/data/amz_real_data/kat_walks.arff\",\n",
    "    names=attributes,\n",
    "    row_iterator=kat_walks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkt_walks = []\n",
    "attributes = None\n",
    "\n",
    "for walk in flat_walks:\n",
    "    fkt_walks.append(dict(walk.items()))\n",
    "    del fkt_walks[-1][\"user\"]\n",
    "    fkt_walks[-1][\"from\"] = fkt2id[fkt_walks[-1][\"previous_funktion\"]]\n",
    "    del fkt_walks[-1][\"previous_funktion\"]\n",
    "    fkt_walks[-1][\"to\"] = fkt2id[fkt_walks[-1][\"funktion\"]]\n",
    "    del fkt_walks[-1][\"funktion\"]\n",
    "    del fkt_walks[-1][\"previous_kategorie\"]\n",
    "    del fkt_walks[-1][\"kategorie\"]\n",
    "    if attributes is None:\n",
    "        attributes = list(fkt_walks[-1].keys())\n",
    "    else:\n",
    "        assert attributes == list(fkt_walks[-1].keys())\n",
    "    fkt_walks[-1] = list(fkt_walks[-1].values())\n",
    "\n",
    "print(fkt_walks[0])\n",
    "\n",
    "arff.dump(\n",
    "    \"/Users/janpf/projects/deeptrails/data/amz_real_data/fkt_walks.arff\",\n",
    "    names=attributes,\n",
    "    row_iterator=fkt_walks,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
